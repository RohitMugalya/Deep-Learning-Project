{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIJddiQ661T9",
        "outputId": "18302388-8b1e-4e1c-a48c-2c27984b1a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlbLW27L6iWU",
        "outputId": "1c1de744-444d-47f9-c81f-b5be5fe2a0b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "Evolutionary EDA & Feature Engineering\n",
            "Dataset: Adult Income (Census)\n",
            "============================================================\n",
            "\n",
            "Data loaded:\n",
            "  Train: 34189 samples, 14 features\n",
            "  Val: 7326 samples\n",
            "  Test: 7327 samples\n",
            "  Missing values: 1587\n",
            "  Class distribution: [28700  5489]\n",
            "\n",
            "Initializing population (size=8)...\n",
            "  Init 1/8: Score=0.6717 | NumImp:med|CatImp:con|Out:none|FE:||B|Enc:fre|Scl:min|FS:True\n",
            "  Init 2/8: Score=0.6549 | NumImp:med|CatImp:con|Out:zscore|FE:I|R||Enc:lab|Scl:sta|FS:True\n",
            "  Init 3/8: Score=0.6872 | NumImp:med|CatImp:con|Out:zscore|FE:I|||Enc:fre|Scl:sta|FS:True\n",
            "  Init 4/8: Score=0.6762 | NumImp:med|CatImp:con|Out:zscore|FE:I||B|Enc:fre|Scl:sta|FS:True\n",
            "  Init 5/8: Score=0.6630 | NumImp:mea|CatImp:mod|Out:clip|FE:||B|Enc:lab|Scl:sta|FS:False\n",
            "  Init 6/8: Score=0.5607 | NumImp:mod|CatImp:con|Out:iqr|FE:|R|B|Enc:fre|Scl:non|FS:False\n",
            "  Init 7/8: Score=0.6370 | NumImp:med|CatImp:con|Out:none|FE:I||B|Enc:lab|Scl:sta|FS:True\n",
            "  Init 8/8: Score=0.6678 | NumImp:mea|CatImp:con|Out:none|FE:|R||Enc:fre|Scl:min|FS:True\n",
            "\n",
            "============================================================\n",
            "Generation 1/5\n",
            "============================================================\n",
            "  Best Score: 0.6872\n",
            "  Config: NumImp:med|CatImp:con|Out:zscore|FE:I|||Enc:fre|Scl:sta|FS:True\n",
            "\n",
            "============================================================\n",
            "Generation 2/5\n",
            "============================================================\n",
            "  Best Score: 0.6872\n",
            "  Config: NumImp:med|CatImp:con|Out:zscore|FE:I|||Enc:fre|Scl:sta|FS:True\n",
            "\n",
            "============================================================\n",
            "Generation 3/5\n",
            "============================================================\n",
            "  Best Score: 0.6872\n",
            "  Config: NumImp:med|CatImp:con|Out:zscore|FE:I|||Enc:fre|Scl:sta|FS:True\n",
            "\n",
            "============================================================\n",
            "Generation 4/5\n",
            "============================================================\n",
            "  Best Score: 0.6872\n",
            "  Config: NumImp:med|CatImp:con|Out:zscore|FE:I|||Enc:fre|Scl:sta|FS:True\n",
            "\n",
            "============================================================\n",
            "Generation 5/5\n",
            "============================================================\n",
            "  Best Score: 0.6872\n",
            "  Config: NumImp:med|CatImp:con|Out:zscore|FE:I|||Enc:fre|Scl:sta|FS:True\n",
            "\n",
            "============================================================\n",
            "FINAL EVALUATION\n",
            "============================================================\n",
            "\n",
            "Best Configuration:\n",
            "  numeric_impute: median\n",
            "  categorical_impute: constant\n",
            "  outlier_method: zscore\n",
            "  outlier_threshold: 2.0\n",
            "  create_interactions: True\n",
            "  create_ratios: False\n",
            "  create_binning: False\n",
            "  n_bins: 5\n",
            "  categorical_encoding: frequency\n",
            "  scaling: standard\n",
            "  feature_selection: True\n",
            "  selection_threshold: 0.05\n",
            "\n",
            "Final Performance:\n",
            "  Validation Accuracy: 0.7628\n",
            "  Validation F1: 0.5110\n",
            "  Test Accuracy: 0.7594\n",
            "  Test F1: 0.5049\n",
            "  Final Features: 5\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Evolutionary EDA & Feature Engineering - FIXED\n",
        "Dataset: Adult Income (has missing values, mixed types, needs feature engineering)\n",
        "\"\"\"\n",
        "\n",
        "import copy\n",
        "import random\n",
        "from collections import namedtuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# ----------------------------\n",
        "# EDA Configuration Space\n",
        "# ----------------------------\n",
        "\n",
        "def random_eda_config():\n",
        "    \"\"\"Generate random EDA/preprocessing configuration\"\"\"\n",
        "    return {\n",
        "        # Missing value handling\n",
        "        'numeric_impute': random.choice(['mean', 'median', 'mode']),  # Removed 'drop' to avoid index issues\n",
        "        'categorical_impute': random.choice(['mode', 'constant']),  # Removed 'drop'\n",
        "\n",
        "        # Outlier handling\n",
        "        'outlier_method': random.choice(['none', 'iqr', 'zscore', 'clip']),\n",
        "        'outlier_threshold': random.choice([1.5, 2.0, 3.0]),\n",
        "\n",
        "        # Feature engineering\n",
        "        'create_interactions': random.choice([True, False]),\n",
        "        'create_ratios': random.choice([True, False]),\n",
        "        'create_binning': random.choice([True, False]),\n",
        "        'n_bins': random.choice([3, 5, 10]),\n",
        "\n",
        "        # Encoding (removed onehot due to inconsistency issues)\n",
        "        'categorical_encoding': random.choice(['label', 'frequency']),\n",
        "\n",
        "        # Scaling\n",
        "        'scaling': random.choice(['standard', 'minmax', 'none']),\n",
        "\n",
        "        # Feature selection after engineering\n",
        "        'feature_selection': random.choice([True, False]),\n",
        "        'selection_threshold': random.choice([0.01, 0.05, 0.1]),\n",
        "    }\n",
        "\n",
        "def config_to_str(config):\n",
        "    \"\"\"Readable string representation\"\"\"\n",
        "    parts = []\n",
        "    parts.append(f\"NumImp:{config['numeric_impute'][:3]}\")\n",
        "    parts.append(f\"CatImp:{config['categorical_impute'][:3]}\")\n",
        "    parts.append(f\"Out:{config['outlier_method']}\")\n",
        "    parts.append(f\"FE:{'I' if config['create_interactions'] else ''}\")\n",
        "    parts.append(f\"{'R' if config['create_ratios'] else ''}\")\n",
        "    parts.append(f\"{'B' if config['create_binning'] else ''}\")\n",
        "    parts.append(f\"Enc:{config['categorical_encoding'][:3]}\")\n",
        "    parts.append(f\"Scl:{config['scaling'][:3]}\")\n",
        "    parts.append(f\"FS:{config['feature_selection']}\")\n",
        "    return '|'.join(parts)\n",
        "\n",
        "# ----------------------------\n",
        "# EDA Pipeline\n",
        "# ----------------------------\n",
        "\n",
        "class EDA_Pipeline:\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "        self.numeric_imputer = None\n",
        "        self.categorical_imputer = None\n",
        "        self.scaler = None\n",
        "        self.label_encoders = {}\n",
        "        self.feature_names = []\n",
        "        self.selected_features = None\n",
        "        self.numeric_cols = []\n",
        "        self.categorical_cols = []\n",
        "        self.rf_model = None\n",
        "\n",
        "    def identify_column_types(self, X):\n",
        "        \"\"\"Identify numeric and categorical columns\"\"\"\n",
        "        self.numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        self.categorical_cols = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "    def handle_missing_values(self, X, fit=True):\n",
        "        \"\"\"Handle missing values in numeric and categorical columns\"\"\"\n",
        "        X = X.copy()\n",
        "\n",
        "        # Numeric imputation\n",
        "        if len(self.numeric_cols) > 0:\n",
        "            strategy = self.config['numeric_impute']\n",
        "            if strategy == 'mode':\n",
        "                strategy = 'most_frequent'\n",
        "            if fit:\n",
        "                self.numeric_imputer = SimpleImputer(strategy=strategy)\n",
        "                X[self.numeric_cols] = self.numeric_imputer.fit_transform(X[self.numeric_cols])\n",
        "            else:\n",
        "                X[self.numeric_cols] = self.numeric_imputer.transform(X[self.numeric_cols])\n",
        "\n",
        "        # Categorical imputation\n",
        "        if len(self.categorical_cols) > 0:\n",
        "            if self.config['categorical_impute'] == 'mode':\n",
        "                if fit:\n",
        "                    self.categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
        "                    X[self.categorical_cols] = self.categorical_imputer.fit_transform(X[self.categorical_cols])\n",
        "                else:\n",
        "                    X[self.categorical_cols] = self.categorical_imputer.transform(X[self.categorical_cols])\n",
        "            else:  # constant\n",
        "                if fit:\n",
        "                    self.categorical_imputer = SimpleImputer(strategy='constant', fill_value='missing')\n",
        "                    X[self.categorical_cols] = self.categorical_imputer.fit_transform(X[self.categorical_cols])\n",
        "                else:\n",
        "                    X[self.categorical_cols] = self.categorical_imputer.transform(X[self.categorical_cols])\n",
        "\n",
        "        return X\n",
        "\n",
        "    def handle_outliers(self, X, fit=True):\n",
        "        \"\"\"Handle outliers in numeric columns\"\"\"\n",
        "        X = X.copy()\n",
        "\n",
        "        if self.config['outlier_method'] == 'none' or len(self.numeric_cols) == 0:\n",
        "            return X\n",
        "\n",
        "        for col in self.numeric_cols:\n",
        "            if self.config['outlier_method'] == 'iqr':\n",
        "                Q1 = X[col].quantile(0.25)\n",
        "                Q3 = X[col].quantile(0.75)\n",
        "                IQR = Q3 - Q1\n",
        "                lower = Q1 - self.config['outlier_threshold'] * IQR\n",
        "                upper = Q3 + self.config['outlier_threshold'] * IQR\n",
        "                X[col] = X[col].clip(lower, upper)\n",
        "\n",
        "            elif self.config['outlier_method'] == 'zscore':\n",
        "                mean = X[col].mean()\n",
        "                std = X[col].std()\n",
        "                if std > 0:\n",
        "                    threshold = self.config['outlier_threshold']\n",
        "                    X[col] = X[col].clip(mean - threshold * std, mean + threshold * std)\n",
        "\n",
        "            elif self.config['outlier_method'] == 'clip':\n",
        "                lower = X[col].quantile(0.01)\n",
        "                upper = X[col].quantile(0.99)\n",
        "                X[col] = X[col].clip(lower, upper)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def feature_engineering(self, X):\n",
        "        \"\"\"Create new features\"\"\"\n",
        "        X = X.copy()\n",
        "\n",
        "        # Get current numeric columns (after encoding)\n",
        "        current_numeric = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if len(current_numeric) < 2:\n",
        "            return X\n",
        "\n",
        "        # Limit to first few columns to avoid explosion\n",
        "        cols_to_use = current_numeric[:min(5, len(current_numeric))]\n",
        "\n",
        "        # Interaction features\n",
        "        if self.config['create_interactions']:\n",
        "            for i in range(len(cols_to_use)):\n",
        "                for j in range(i+1, len(cols_to_use)):\n",
        "                    col1, col2 = cols_to_use[i], cols_to_use[j]\n",
        "                    X[f'{col1}_x_{col2}'] = X[col1] * X[col2]\n",
        "\n",
        "        # Ratio features\n",
        "        if self.config['create_ratios']:\n",
        "            for i in range(len(cols_to_use)):\n",
        "                for j in range(i+1, len(cols_to_use)):\n",
        "                    col1, col2 = cols_to_use[i], cols_to_use[j]\n",
        "                    X[f'{col1}_div_{col2}'] = X[col1] / (X[col2].abs() + 1e-5)\n",
        "\n",
        "        # Binning\n",
        "        if self.config['create_binning']:\n",
        "            for col in cols_to_use[:3]:\n",
        "                try:\n",
        "                    X[f'{col}_binned'] = pd.cut(X[col], bins=self.config['n_bins'], labels=False, duplicates='drop')\n",
        "                except:\n",
        "                    pass  # Skip if binning fails\n",
        "\n",
        "        return X\n",
        "\n",
        "    def encode_categorical(self, X, fit=True):\n",
        "        \"\"\"Encode categorical variables\"\"\"\n",
        "        X = X.copy()\n",
        "\n",
        "        if len(self.categorical_cols) == 0:\n",
        "            return X\n",
        "\n",
        "        if self.config['categorical_encoding'] == 'label':\n",
        "            for col in self.categorical_cols:\n",
        "                if fit:\n",
        "                    le = LabelEncoder()\n",
        "                    X[col] = le.fit_transform(X[col].astype(str))\n",
        "                    self.label_encoders[col] = le\n",
        "                else:\n",
        "                    le = self.label_encoders.get(col)\n",
        "                    if le:\n",
        "                        # Handle unseen categories\n",
        "                        X[col] = X[col].astype(str).apply(lambda x: x if x in le.classes_ else le.classes_[0])\n",
        "                        X[col] = le.transform(X[col])\n",
        "\n",
        "        elif self.config['categorical_encoding'] == 'frequency':\n",
        "            for col in self.categorical_cols:\n",
        "                if fit:\n",
        "                    freq_map = X[col].value_counts(normalize=True).to_dict()\n",
        "                    self.label_encoders[col] = freq_map\n",
        "                    X[col] = X[col].map(freq_map).fillna(0)\n",
        "                else:\n",
        "                    freq_map = self.label_encoders.get(col, {})\n",
        "                    X[col] = X[col].map(freq_map).fillna(0)\n",
        "\n",
        "        return X\n",
        "\n",
        "    def scale_features(self, X, fit=True):\n",
        "        \"\"\"Scale numeric features\"\"\"\n",
        "        X = X.copy()\n",
        "\n",
        "        if self.config['scaling'] == 'none':\n",
        "            return X\n",
        "\n",
        "        numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "        if len(numeric_cols) == 0:\n",
        "            return X\n",
        "\n",
        "        if self.config['scaling'] == 'standard':\n",
        "            if fit:\n",
        "                self.scaler = StandardScaler()\n",
        "                X[numeric_cols] = self.scaler.fit_transform(X[numeric_cols])\n",
        "            else:\n",
        "                X[numeric_cols] = self.scaler.transform(X[numeric_cols])\n",
        "\n",
        "        elif self.config['scaling'] == 'minmax':\n",
        "            if fit:\n",
        "                self.scaler = MinMaxScaler()\n",
        "                X[numeric_cols] = self.scaler.fit_transform(X[numeric_cols])\n",
        "            else:\n",
        "                X[numeric_cols] = self.scaler.transform(X[numeric_cols])\n",
        "\n",
        "        return X\n",
        "\n",
        "    def select_features(self, X, y, fit=True):\n",
        "        \"\"\"Select important features using Random Forest\"\"\"\n",
        "        X = X.copy()\n",
        "\n",
        "        if not self.config['feature_selection']:\n",
        "            return X\n",
        "\n",
        "        if fit:\n",
        "            # Train RF to get feature importances\n",
        "            self.rf_model = RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1)\n",
        "            self.rf_model.fit(X, y)\n",
        "\n",
        "            importances = pd.Series(self.rf_model.feature_importances_, index=X.columns)\n",
        "            threshold = self.config['selection_threshold']\n",
        "            self.selected_features = importances[importances >= threshold].index.tolist()\n",
        "\n",
        "            # Keep at least 5 features\n",
        "            if len(self.selected_features) < 5:\n",
        "                self.selected_features = importances.nlargest(10).index.tolist()\n",
        "\n",
        "            return X[self.selected_features]\n",
        "        else:\n",
        "            # Use only selected features\n",
        "            if self.selected_features:\n",
        "                available_features = [f for f in self.selected_features if f in X.columns]\n",
        "                if len(available_features) > 0:\n",
        "                    return X[available_features]\n",
        "            return X\n",
        "\n",
        "    def fit_transform(self, X, y):\n",
        "        \"\"\"Fit and transform training data\"\"\"\n",
        "        # Ensure X is a DataFrame\n",
        "        if isinstance(X, np.ndarray):\n",
        "            X = pd.DataFrame(X)\n",
        "\n",
        "        X = X.reset_index(drop=True)\n",
        "        y = pd.Series(y).reset_index(drop=True)\n",
        "\n",
        "        self.identify_column_types(X)\n",
        "        X = self.handle_missing_values(X, fit=True)\n",
        "        X = self.handle_outliers(X, fit=True)\n",
        "        X = self.encode_categorical(X, fit=True)\n",
        "        X = self.feature_engineering(X)\n",
        "        X = self.scale_features(X, fit=True)\n",
        "        X = self.select_features(X, y.values, fit=True)\n",
        "\n",
        "        # Replace inf and nan\n",
        "        X = X.replace([np.inf, -np.inf], np.nan)\n",
        "        X = X.fillna(0)\n",
        "\n",
        "        return X.values, y.values\n",
        "\n",
        "    def transform(self, X):\n",
        "        \"\"\"Transform validation/test data\"\"\"\n",
        "        # Ensure X is a DataFrame\n",
        "        if isinstance(X, np.ndarray):\n",
        "            X = pd.DataFrame(X)\n",
        "\n",
        "        X = X.reset_index(drop=True)\n",
        "\n",
        "        X = self.handle_missing_values(X, fit=False)\n",
        "        X = self.handle_outliers(X, fit=False)\n",
        "        X = self.encode_categorical(X, fit=False)\n",
        "        X = self.feature_engineering(X)\n",
        "        X = self.scale_features(X, fit=False)\n",
        "\n",
        "        # Handle feature selection\n",
        "        if self.config['feature_selection'] and self.selected_features:\n",
        "            available_features = [f for f in self.selected_features if f in X.columns]\n",
        "            missing_features = [f for f in self.selected_features if f not in X.columns]\n",
        "\n",
        "            # Add missing features with zeros\n",
        "            for f in missing_features:\n",
        "                X[f] = 0\n",
        "\n",
        "            X = X[self.selected_features]\n",
        "\n",
        "        # Replace inf and nan\n",
        "        X = X.replace([np.inf, -np.inf], np.nan)\n",
        "        X = X.fillna(0)\n",
        "\n",
        "        return X.values\n",
        "\n",
        "# ----------------------------\n",
        "# Data Loading\n",
        "# ----------------------------\n",
        "\n",
        "def load_adult_income_data():\n",
        "    \"\"\"Load Adult Income dataset (has missing values, mixed types)\"\"\"\n",
        "    adult = fetch_ucirepo(id=2)\n",
        "    X = adult.data.features\n",
        "    y = adult.data.targets\n",
        "\n",
        "    # Convert target to binary\n",
        "    y = (y['income'] == '>50K').astype(int).values\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "# ----------------------------\n",
        "# Model Training & Evaluation\n",
        "# ----------------------------\n",
        "\n",
        "def train_and_evaluate(X_train, y_train, X_val, y_val):\n",
        "    \"\"\"Train simple model and return validation score\"\"\"\n",
        "    try:\n",
        "        # Use Logistic Regression with class balancing\n",
        "        model = LogisticRegression(max_iter=1000, random_state=42, n_jobs=-1, class_weight='balanced')\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        y_pred = model.predict(X_val)\n",
        "        acc = accuracy_score(y_val, y_pred)\n",
        "        f1 = f1_score(y_val, y_pred, zero_division=0)\n",
        "\n",
        "        # Use weighted score\n",
        "        score = 0.7 * acc + 0.3 * f1\n",
        "\n",
        "        return score\n",
        "    except Exception as e:\n",
        "        print(f\"  Error in training: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# ----------------------------\n",
        "# Evolutionary Algorithm\n",
        "# ----------------------------\n",
        "\n",
        "Individual = namedtuple('Individual', ['config', 'fitness', 'pipeline'])\n",
        "\n",
        "def mutate_config(config):\n",
        "    \"\"\"Mutate EDA configuration\"\"\"\n",
        "    new = copy.deepcopy(config)\n",
        "\n",
        "    # Randomly select field to mutate\n",
        "    field = random.choice([\n",
        "        'numeric_impute', 'categorical_impute', 'outlier_method', 'outlier_threshold',\n",
        "        'create_interactions', 'create_ratios', 'create_binning', 'n_bins',\n",
        "        'categorical_encoding', 'scaling', 'feature_selection', 'selection_threshold'\n",
        "    ])\n",
        "\n",
        "    if field == 'numeric_impute':\n",
        "        new['numeric_impute'] = random.choice(['mean', 'median', 'mode'])\n",
        "    elif field == 'categorical_impute':\n",
        "        new['categorical_impute'] = random.choice(['mode', 'constant'])\n",
        "    elif field == 'outlier_method':\n",
        "        new['outlier_method'] = random.choice(['none', 'iqr', 'zscore', 'clip'])\n",
        "    elif field == 'outlier_threshold':\n",
        "        new['outlier_threshold'] = random.choice([1.5, 2.0, 3.0])\n",
        "    elif field == 'create_interactions':\n",
        "        new['create_interactions'] = not new['create_interactions']\n",
        "    elif field == 'create_ratios':\n",
        "        new['create_ratios'] = not new['create_ratios']\n",
        "    elif field == 'create_binning':\n",
        "        new['create_binning'] = not new['create_binning']\n",
        "    elif field == 'n_bins':\n",
        "        new['n_bins'] = random.choice([3, 5, 10])\n",
        "    elif field == 'categorical_encoding':\n",
        "        new['categorical_encoding'] = random.choice(['label', 'frequency'])\n",
        "    elif field == 'scaling':\n",
        "        new['scaling'] = random.choice(['standard', 'minmax', 'none'])\n",
        "    elif field == 'feature_selection':\n",
        "        new['feature_selection'] = not new['feature_selection']\n",
        "    elif field == 'selection_threshold':\n",
        "        new['selection_threshold'] = random.choice([0.01, 0.05, 0.1])\n",
        "\n",
        "    return new\n",
        "\n",
        "def evolve(population, X_train, y_train, X_val, y_val, args):\n",
        "    \"\"\"Evolve population for one generation\"\"\"\n",
        "    population = sorted(population, key=lambda x: x.fitness if x.fitness is not None else 0.0, reverse=True)\n",
        "    next_pop = []\n",
        "\n",
        "    # Elitism\n",
        "    K = max(1, int(args.elitism * len(population)))\n",
        "    next_pop.extend(population[:K])\n",
        "\n",
        "    # Generate children\n",
        "    while len(next_pop) < args.pop_size:\n",
        "        # Tournament selection\n",
        "        tournament = random.sample(population, k=min(args.tournament_k, len(population)))\n",
        "        parent = max(tournament, key=lambda x: x.fitness if x.fitness is not None else 0.0)\n",
        "\n",
        "        # Mutate\n",
        "        child_config = mutate_config(parent.config)\n",
        "\n",
        "        # Apply EDA pipeline\n",
        "        try:\n",
        "            pipeline = EDA_Pipeline(child_config)\n",
        "            X_train_proc, y_train_proc = pipeline.fit_transform(X_train.copy(), y_train.copy())\n",
        "            X_val_proc = pipeline.transform(X_val.copy())\n",
        "\n",
        "            # Train and evaluate\n",
        "            fitness = train_and_evaluate(X_train_proc, y_train_proc, X_val_proc, y_val)\n",
        "\n",
        "            child = Individual(config=child_config, fitness=fitness, pipeline=pipeline)\n",
        "            next_pop.append(child)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing child: {e}\")\n",
        "            # Add parent instead to maintain population size\n",
        "            if len(next_pop) < args.pop_size:\n",
        "                next_pop.append(parent)\n",
        "\n",
        "    return next_pop[:args.pop_size]\n",
        "\n",
        "# ----------------------------\n",
        "# Main Evolution\n",
        "# ----------------------------\n",
        "\n",
        "def run_evo_eda(args):\n",
        "    print(\"=\"*60)\n",
        "    print(\"Evolutionary EDA & Feature Engineering\")\n",
        "    print(\"Dataset: Adult Income (Census)\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Load data\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test = load_adult_income_data()\n",
        "    print(f\"\\nData loaded:\")\n",
        "    print(f\"  Train: {len(X_train)} samples, {X_train.shape[1]} features\")\n",
        "    print(f\"  Val: {len(X_val)} samples\")\n",
        "    print(f\"  Test: {len(X_test)} samples\")\n",
        "    print(f\"  Missing values: {X_train.isnull().sum().sum()}\")\n",
        "    print(f\"  Class distribution: {np.bincount(y_train)}\")\n",
        "\n",
        "    # Initialize population\n",
        "    population = []\n",
        "    print(f\"\\nInitializing population (size={args.pop_size})...\")\n",
        "    for i in range(args.pop_size):\n",
        "        config = random_eda_config()\n",
        "\n",
        "        try:\n",
        "            pipeline = EDA_Pipeline(config)\n",
        "            X_train_proc, y_train_proc = pipeline.fit_transform(X_train.copy(), y_train.copy())\n",
        "            X_val_proc = pipeline.transform(X_val.copy())\n",
        "\n",
        "            fitness = train_and_evaluate(X_train_proc, y_train_proc, X_val_proc, y_val)\n",
        "\n",
        "            population.append(Individual(config=config, fitness=fitness, pipeline=pipeline))\n",
        "            print(f\"  Init {i+1}/{args.pop_size}: Score={fitness:.4f} | {config_to_str(config)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Init {i+1}/{args.pop_size}: FAILED - {e}\")\n",
        "\n",
        "    # Evolution\n",
        "    best = None\n",
        "    for gen in range(1, args.generations + 1):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Generation {gen}/{args.generations}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        population = evolve(population, X_train, y_train, X_val, y_val, args)\n",
        "        population = sorted(population, key=lambda x: x.fitness if x.fitness is not None else 0.0, reverse=True)\n",
        "\n",
        "        best = population[0]\n",
        "        print(f\"  Best Score: {best.fitness:.4f}\")\n",
        "        print(f\"  Config: {config_to_str(best.config)}\")\n",
        "\n",
        "    # Final test\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"FINAL EVALUATION\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    X_train_final, y_train_final = best.pipeline.fit_transform(X_train.copy(), y_train.copy())\n",
        "    X_test_final = best.pipeline.transform(X_test.copy())\n",
        "\n",
        "    model = LogisticRegression(max_iter=1000, random_state=42, class_weight='balanced')\n",
        "    model.fit(X_train_final, y_train_final)\n",
        "\n",
        "    y_pred_val = model.predict(best.pipeline.transform(X_val.copy()))\n",
        "    y_pred_test = model.predict(X_test_final)\n",
        "\n",
        "    val_acc = accuracy_score(y_val, y_pred_val)\n",
        "    val_f1 = f1_score(y_val, y_pred_val, zero_division=0)\n",
        "    test_acc = accuracy_score(y_test, y_pred_test)\n",
        "    test_f1 = f1_score(y_test, y_pred_test, zero_division=0)\n",
        "\n",
        "    print(f\"\\nBest Configuration:\")\n",
        "    for key, value in best.config.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "\n",
        "    print(f\"\\nFinal Performance:\")\n",
        "    print(f\"  Validation Accuracy: {val_acc:.4f}\")\n",
        "    print(f\"  Validation F1: {val_f1:.4f}\")\n",
        "    print(f\"  Test Accuracy: {test_acc:.4f}\")\n",
        "    print(f\"  Test F1: {test_f1:.4f}\")\n",
        "    print(f\"  Final Features: {X_train_final.shape[1]}\")\n",
        "\n",
        "    return best\n",
        "\n",
        "# ----------------------------\n",
        "# Run\n",
        "# ----------------------------\n",
        "\n",
        "class Args:\n",
        "    pop_size = 8\n",
        "    generations = 5\n",
        "    elitism = 0.25\n",
        "    tournament_k = 3\n",
        "\n",
        "args = Args()\n",
        "best_config = run_evo_eda(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M9fqY_X76sld"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}